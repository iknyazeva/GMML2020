{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BVJG6NI6rmAf"
   },
   "source": [
    "PCA\n",
    "$$\n",
    "a_i = argmin_{\\| a \\| = 1} \\sum_{i=1}^n (x_i - a^T x_i a)^2\n",
    "$$\n",
    "It is sensitive to ouliers, because of sum of squares. Why not to try to find new components by minimizing not sum of squares with a help of another distance...?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gwjLsmrrszbq"
   },
   "source": [
    "We are going to do the same things as in PCA, but with different approaches in computing means and new components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wou65DO8imYW"
   },
   "source": [
    "![alt text](https://i.ibb.co/0hmqr1f/image.png)\n",
    "\n",
    "\n",
    "Left: A zero-mean dataset represented as a set of points.\n",
    "Center: The same data represented as a set of one-dimensional\n",
    "subspaces. Right: The blue dotted subspace is the average.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RsZB7npRkesl"
   },
   "source": [
    "Note that here we are speaking about feature-outliers. A simple example is burnt pixel in an image.\n",
    "![alt text](https://cs8.pikabu.ru/post_img/big/2016/04/27/6/1461749915137084224.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0PVv5AIGjmyD"
   },
   "source": [
    "**Definition 1** The Grassman Manifold $Gr(k,D)$ is the space of all $k$-dimensional subspaces of $\\mathbb{R}^D$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TR295hd5ooWh"
   },
   "source": [
    "In fact, we will need only $Gr(1, D)$. Which is isomorphic to the following set:\n",
    "$$\n",
    "[u] = \\{u, -u \\}, ~ \\| u \\| = 1.\n",
    "$$\n",
    "This manifold also can be written as the quotient \n",
    "$$\n",
    "S^{D-1} / \\{ \\pm 1 \\}.\n",
    "$$\n",
    "See \"J. Lee. Introduction to Smooth Manifolds. Springer, 2002. 3\" for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-uMgLf3rZMGj"
   },
   "source": [
    "![alt text](https://i.ibb.co/Wv4ggjW/image.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MexEjXqetfSB"
   },
   "source": [
    "From now we live on the $Gr(1,D)$. Thus, we need a kind of a squared distance here. Particularly, for the computation of new components.\n",
    "$$\n",
    "dist^2_{S^{D-1}}(u_1, u_2) = \\frac{1}{2} \\| u_1 - u_2 \\|^2 = 1 - u_1^T u_2.\n",
    "$$\n",
    "Weighted average for this distance is\n",
    "$$\n",
    "q = \\frac{\\mu(\\omega_{1:N}, u_{1:N})}{\\| \\mu(\\omega_{1:N}, u_{1:N}) \\|},\n",
    "$$\n",
    "here $u_n = \\frac{x_n}{\\| x_n \\|}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iMiIY9NsY-bp"
   },
   "source": [
    "Moreover, we can choose another mean function $\\mu_{rob}(\\omega, u)$, such that it will possess desired robustness properties. For example, we can use trimmed mean.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hsnw1jiqZ9m9"
   },
   "source": [
    "TrimmedMean$([a_1, a_2, a_3, a_4, a_5], 20\\%) = \\frac{1}{3} \\sum_{i=2}^4 a_i$\n",
    "\n",
    "TrimmedMean$([a_1, a_2, a_3, a_4, a_5], 50\\%) =$ Median$([a_1, a_2, a_3, a_4, a_5]) = a_3$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jXvfw80dX4SP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.utils import as_float_array, check_array, check_random_state\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8yx5SZC6lWvX"
   },
   "source": [
    "Now we are going to implement a class that is computing principal component is the robust way, using Trimmed Mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uuW_Q9_rkFjS"
   },
   "source": [
    "In practice, it is more convenient to wipe out according to the $k$th smallest and $k$th largest:\n",
    "TrimmedMean$([a_1, a_2, a_3, a_4, a_5], 1) = \\frac{1}{3} \\sum_{i=2}^4 a_i$\n",
    "\n",
    "TrimmedMean$([a_1, a_2, a_3, a_4, a_5], 2) = a_3$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6x_qfaRWX6VE"
   },
   "outputs": [],
   "source": [
    "def _trimmed_mean_1d(arr, k):\n",
    "    \"\"\"Calculate trimmed mean on a 1d array.\n",
    "\n",
    "    Trim values largest than the k'th largest value or smaller than the k'th\n",
    "    smallest value\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr: ndarray, shape (n,)\n",
    "        The one-dimensional input array to perform trimmed mean on\n",
    "\n",
    "    k: int\n",
    "        The thresholding order for trimmed mean\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    trimmed_mean: float\n",
    "        The trimmed mean calculated\n",
    "    \"\"\"\n",
    "    kth_smallest = np.partition(arr, k)[k-1]\n",
    "    kth_largest = -np.partition(-arr, k)[k-1]\n",
    "\n",
    "    ########################\n",
    "    #code here!\n",
    "    ########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xmvdwyiWme7f"
   },
   "outputs": [],
   "source": [
    "### test your might\n",
    "test_array = np.array([1, 2, 3, 7, 5])\n",
    "ans = _trimmed_mean_1d(test_array, 0)\n",
    "assert ans == 5.0, \"Something is wrong...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t-T9wxpgmatA"
   },
   "source": [
    "Now, we can simply apply this for the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P3jeB8aYYBBJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _trimmed_mean(X, trim_proportion):\n",
    "    \"\"\"Calculate trimmed mean on each column of input matrix\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: ndarray, shape (n_samples, n_features)\n",
    "        The input matrix to perform trimmed mean on\n",
    "\n",
    "    trim_proportion: float\n",
    "        The proportion of trim. Largest and smallest 'trim_proportion' are\n",
    "        trimmed when calculating the mean.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    trimmed_mean: ndarray, shape (n_features,)\n",
    "        The trimmed mean calculated on each column\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    n_trim = int(n_samples * trim_proportion)\n",
    "    return np.apply_along_axis(_trimmed_mean_1d, 0, X, k=n_trim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n1rDavF2oo_M"
   },
   "source": [
    "Also, we will need supplementary function for reorthogonalization of the components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TOSjJhXXYBrU"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _reorth(basis, target, rows=None, alpha=0.5):\n",
    "    \"\"\"Reorthogonalize a vector using iterated Gram-Schmidt\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    basis: ndarray, shape (n_features, n_basis)\n",
    "        The matrix whose rows are a set of basis to reorthogonalize against\n",
    "\n",
    "    target: ndarray, shape (n_features,)\n",
    "        The target vector to be reorthogonalized\n",
    "\n",
    "    rows: {array-like, None}, default None\n",
    "        Indices of rows from basis to use. Use all if None\n",
    "\n",
    "    alpha: float, default 0.5\n",
    "        Parameter for determining whether to do a second reorthogonalization.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    reorthed_target: ndarray, shape (n_features,)\n",
    "        The reorthogonalized vector\n",
    "    \"\"\"\n",
    "    if rows is not None:\n",
    "        basis = basis[rows]\n",
    "    norm_target = np.linalg.norm(target)\n",
    "\n",
    "    norm_target_old = 0\n",
    "    n_reorth = 0\n",
    "\n",
    "    while norm_target < alpha * norm_target_old or n_reorth == 0:\n",
    "        for row in basis:\n",
    "            t = np.dot(row, target)\n",
    "            target = target - t * row\n",
    "\n",
    "        norm_target_old = norm_target\n",
    "        norm_target = np.linalg.norm(target)\n",
    "        n_reorth += 1\n",
    "\n",
    "        if n_reorth > 4:\n",
    "            # target in span(basis) => accpet target = 0\n",
    "            target = np.zeros(basis.shape[0])\n",
    "            break\n",
    "\n",
    "    return target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eqCD99Hsqw-Q"
   },
   "source": [
    "Now there is a big job below: code that `TGA` class. It has a structure based on `PCA` from `sklearn`, so there is a lot of methods but we will pay attention only on the key one which is `._fit`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "maZTl0gsrWqn"
   },
   "source": [
    "The key part of this method is computation of the next TGA component. It is to be computed in accordance to the following formula:\n",
    "$$\n",
    "\\omega_n \\leftarrow sign(u_n^T q_{i-1}); ~ q_i \\leftarrow \\frac{\\mu_{rob}(\\omega_{1:N}, u_{1:N})}{\\| \\mu_{rob}(\\omega_{1:N}, u_{1:N}) \\|},\n",
    "$$\n",
    "here $u_n = \\frac{x_n}{\\| x_n \\|}$.\n",
    "\n",
    "Note that components are being computed based on the previous one.\n",
    "\n",
    "There is another strategy for finding principal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UZYo6O7yxIVx"
   },
   "source": [
    "Below we will implement the most valuable of the `._fit` method that is computation of the next component. The other part are technical routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dZK0ZgWexFxK"
   },
   "outputs": [],
   "source": [
    "def get_new_component(k, prev_components, X, n_features, n_samples, trim_proportion, tol):\n",
    "  if k == 0:\n",
    "    # initialize using a few EM iterations\n",
    "    mu = rng.rand(n_features) - 0.5\n",
    "    mu = mu / np.linalg.norm(mu)\n",
    "    for i in range(3):\n",
    "      dots = np.dot(X, mu)\n",
    "      mu = np.dot(dots.T, X)\n",
    "      mu = mu / np.linalg.norm(mu)\n",
    "\n",
    "  # grassmann average\n",
    "  for i in range(n_samples):\n",
    "    prev_mu = prev_components[k-1]\n",
    "    ########################\n",
    "    #code the formula above\n",
    "    ########################\n",
    "    if np.max(np.abs(mu - prev_mu)) < tol:\n",
    "      break\n",
    "\n",
    "  #possibly re-orthonormalize\n",
    "  if k > 0:\n",
    "      mu = _reorth(prev_components[:k-1], mu)\n",
    "      mu = mu / np.linalg.norm(mu)\n",
    "  return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QT6XvrzDzr47"
   },
   "outputs": [],
   "source": [
    "# test your might\n",
    "X_tst  = np.array([[1, 2, 3, 7], [112, 113 , 114, 123], [10, 22, -123, 57]])\n",
    "prev_components_tst = [1, 1, 2]\n",
    "n_samples_tst, n_features_tst = X_tst.shape\n",
    "ans_tst = get_new_component(1, prev_components_tst, X_tst, n_features_tst, n_samples_tst, 0.1, 1e-5)\n",
    "assert (np.linalg.norm(ans_tst - np.array([0.16152159, 0.35534751, 0., 0.92067308])) < 1e-8), \"Something is wrong...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jgzaLMNS8gsX"
   },
   "source": [
    "I have gathered all the code in one file for you, now let us go after the experiments!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "coding_tga.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
