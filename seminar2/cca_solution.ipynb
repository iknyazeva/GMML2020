{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical CCA: Practice#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is short practical part of introduction to CCA. Here we will work with NYC school dataset. We will have two groups of variables. One group will be measures of quality of education environment at particular school, other group will contain measures of students performance. We will find 2 canonical directions for our sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start from importing all packages and downloading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('./data/2016 School Explorer.csv')\n",
    "# choose relevant features\n",
    "df = df[['Rigorous Instruction %',\n",
    "      'Collaborative Teachers %',\n",
    "     'Supportive Environment %',\n",
    "       'Effective School Leadership %',\n",
    "   'Strong Family-Community Ties %',\n",
    "    'Trust %','Average ELA Proficiency',\n",
    "       'Average Math Proficiency']]\n",
    "# drop missing values\n",
    "df = df.dropna()\n",
    "# separate X and Y groups\n",
    "X = df[['Rigorous Instruction %',\n",
    "      'Collaborative Teachers %',\n",
    "     'Supportive Environment %',\n",
    "       'Effective School Leadership %',\n",
    "   'Strong Family-Community Ties %',\n",
    "    'Trust %'\n",
    "      ]]\n",
    "Y = df[['Average ELA Proficiency',\n",
    "       'Average Math Proficiency']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at groups of variables. Easy question - can more than two canonical directions be found there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will do scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-8b173fbda087>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = X[col].str.strip('%')\n",
      "<ipython-input-2-8b173fbda087>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = X[col].astype('int')\n"
     ]
    }
   ],
   "source": [
    "for col in X.columns:\n",
    "    X[col] = X[col].str.strip('%')\n",
    "    X[col] = X[col].astype('int')\n",
    "# Standardise the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=True, with_std=True)\n",
    "X_sc = sc.fit_transform(X)\n",
    "Y_sc = sc.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets start to code our own implementation of CCA. Here we would not care about efficiency, but just cover the \n",
    "pipline, introduced in theorethical part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1. Compute covariance matrices. You may not care about scaling it with number of instances. Why? What it will\n",
    "affect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute CCA by hands\n",
    "Sigma_XY = np.dot(X_sc.T, Y_sc)\n",
    "Sigma_XX = np.dot(X_sc.T, X_sc)\n",
    "Sigma_YY = np.dot(Y_sc.T, Y_sc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2. Compute inverse of square roots of covariation matrices. It is needed for computetions of A and B matrices and for computing T matrix. Main formulas are provided below \n",
    "\\\n",
    "$$T = \\Sigma_{XX}^{-\\frac{1}{2}}\\Sigma_{XY}\\Sigma_{YY}^{-\\frac{1}{2}} $$\n",
    "\\\n",
    "$$T=U\\Lambda V^T $$\n",
    "\\\n",
    "$$A _k^{k \\times n}= U_k ^T \\Sigma_{XX}^{-\\frac{1}{2}}, \\ B _k^{k \\times m}= V_k ^T \\Sigma_{YY}^{-\\frac{1}{2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_x, L_x = np.linalg.eig(Sigma_XX)\n",
    "Sigma_XX_sqrt_inv = np.linalg.inv(L_x @ np.diag(np.sqrt(S_x)) @ np.linalg.inv(L_x))\n",
    "S_y, L_y = np.linalg.eig(Sigma_YY)\n",
    "Sigma_YY_sqrt_inv = np.linalg.inv(L_y @ np.diag(np.sqrt(S_y)) @ np.linalg.inv(L_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3. Compute T and its SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = Sigma_XX_sqrt_inv @ Sigma_XY @ Sigma_YY_sqrt_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, Vh = np.linalg.svd(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4. Compute A and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = U[:,:2].T@Sigma_XX_sqrt_inv\n",
    "B = Vh[:2,:]@Sigma_YY_sqrt_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5. Compute maximized pairwise correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction_1_x = A.T[:,0]/np.linalg.norm(A.T[:,0])\n",
    "direction_2_x = A.T[:,1]/np.linalg.norm(A.T[:,1])\n",
    "direction_1_y = B.T[:,0]/np.linalg.norm(B.T[:,0])\n",
    "direction_2_y = B.T[:,1]/np.linalg.norm(B.T[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4605990186268907\n",
      "0.18447786228102248\n"
     ]
    }
   ],
   "source": [
    "var_1_by_hands = np.dot(X_sc@direction_1_x,Y_sc@direction_1_y)/np.sqrt(np.dot(X_sc@direction_1_x,X_sc@direction_1_x)*np.dot(Y_sc@direction_1_y,Y_sc@direction_1_y))\n",
    "var_2_by_hands = np.dot(X_sc@direction_2_x,Y_sc@direction_2_y)/np.sqrt(np.dot(X_sc@direction_2_x,X_sc@direction_2_x)*np.dot(Y_sc@direction_2_y,Y_sc@direction_2_y))\n",
    "print(var_1_by_hands)\n",
    "print(var_2_by_hands)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the same thing with package for CCA, and check if everything is done correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import CCA\n",
    "nComponents = 2 # min(p,q) components\n",
    "cca = CCA(n_components=nComponents)\n",
    "cca.fit(X_sc, Y_sc)\n",
    "X_c, Y_c = cca.transform(X_sc, Y_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximized correlation between first pair of canonical variables :  0.46059901511953844\n",
      "Maximized correlation between second pair of canonical variables :  0.18447786368577776\n"
     ]
    }
   ],
   "source": [
    "#Check variances\n",
    "var1 = (X_c.T@Y_c)[0,0]/np.sqrt((X_c.T@X_c)[0,0]*(Y_c.T@Y_c)[0,0])\n",
    "var2 = (X_c.T@Y_c)[1,1]/np.sqrt((X_c.T@X_c)[1,1]*(Y_c.T@Y_c)[1,1])\n",
    "print(\"Maximized correlation between first pair of canonical variables : \", var1)\n",
    "print(\"Maximized correlation between second pair of canonical variables : \", var2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.13341004  0.24115923]\n",
      " [-0.02182311 -0.11012058]\n",
      " [ 0.72897535 -0.25737072]\n",
      " [ 0.44467451  0.91707609]\n",
      " [-0.01654807 -0.27890374]\n",
      " [-0.50230588 -0.38948744]]\n",
      "[[-0.23566075  1.3150408 ]\n",
      " [ 0.97183538 -1.17967538]]\n"
     ]
    }
   ],
   "source": [
    "#Coefficient \n",
    "print(cca.x_rotations_)\n",
    "print(cca.y_rotations_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
